{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GO Term Embedding Generator for CAFA6\n",
    "\n",
    "This notebook generates embeddings for Gene Ontology terms using graph-based features.\n",
    "\n",
    "Outputs: `go_embeddings.npy`, `go_terms.npy`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import obonet\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Data paths\n",
    "data_dir = '/kaggle/input/cafa-6-protein-function-prediction/'\n",
    "go_obo_file = os.path.join(data_dir, 'go-basic.obo')\n",
    "train_terms_file = os.path.join(data_dir, 'train_terms.tsv')\n",
    "\n",
    "# Load GO graph\n",
    "go_graph = obonet.read_obo(go_obo_file)\n",
    "print(f'Loaded GO graph with {len(go_graph.nodes)} nodes')\n",
    "\n",
    "# Load training terms to subset\n",
    "train_terms = pd.read_csv(train_terms_file, sep='\\t', header=None, names=['EntryID', 'term', 'aspect'])\n",
    "go_terms = train_terms['term'].unique()\n",
    "print(f'Unique GO terms in training: {len(go_terms)}')\n",
    "\n",
    "# Subset graph\n",
    "relevant_nodes = set(go_terms)\n",
    "for term in go_terms:\n",
    "    if term in go_graph:\n",
    "        ancestors = nx.ancestors(go_graph, term)\n",
    "        relevant_nodes.update(ancestors)\n",
    "go_subgraph = go_graph.subgraph(relevant_nodes)\n",
    "print(f'Relevant subgraph: {len(go_subgraph.nodes)} nodes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute GO Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features: degree, depth\n",
    "go_features = {}\n",
    "for node in go_subgraph.nodes:\n",
    "    degree = go_subgraph.degree(node)\n",
    "    # Approximate depth\n",
    "    try:\n",
    "        depth = nx.shortest_path_length(go_subgraph, source=list(go_subgraph.nodes)[0], target=node)\n",
    "    except:\n",
    "        depth = 0\n",
    "    go_features[node] = [degree, depth]\n",
    "\n",
    "# To array\n",
    "go_terms_list = list(go_features.keys())\n",
    "features_array = np.array([go_features[term] for term in go_terms_list])\n",
    "\n",
    "# Standardize and PCA to 320 dims\n",
    "scaler = StandardScaler()\n",
    "features_scaled = scaler.fit_transform(features_array)\n",
    "pca = PCA(n_components=320)\n",
    "go_embeddings = pca.fit_transform(features_scaled)\n",
    "\n",
    "print(f'Computed embeddings for {len(go_terms_list)} GO terms, dim: {go_embeddings.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save\n",
    "np.save('/kaggle/working/go_embeddings.npy', go_embeddings)\n",
    "np.save('/kaggle/working/go_terms.npy', np.array(go_terms_list))\n",
    "\n",
    "print('GO embeddings saved to /kaggle/working/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}